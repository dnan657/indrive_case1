import streamlit as st
from ultralytics import YOLO
import torch
from torchvision import models, transforms
from PIL import Image
import io

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
DETECTOR_WEIGHTS_PATH = 'weights/best.pt'
CLASSIFIER_WEIGHTS_PATH = 'weights/cleanliness_classifier_best.pth'
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏) ---
@st.cache_resource
def load_detector():
    model = YOLO(DETECTOR_WEIGHTS_PATH)
    return model

@st.cache_resource
def load_classifier():
    model = models.efficientnet_b0()
    num_ftrs = model.classifier[1].in_features
    model.classifier[1] = torch.nn.Linear(num_ftrs, 1)
    model.load_state_dict(torch.load(CLASSIFIER_WEIGHTS_PATH, map_location=torch.device(DEVICE)))
    model.to(DEVICE)
    model.eval()
    return model

# --- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ---
def predict(image_bytes):
    # 1. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–∏—Å—Ç–æ—Ç—ã
    classifier_model = load_classifier()
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    image_for_classifier = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    img_t = transform(image_for_classifier)
    batch_t = torch.unsqueeze(img_t, 0).to(DEVICE)
    with torch.no_grad():
        output = classifier_model(batch_t)
        prob = torch.sigmoid(output).item()
    
    cleanliness_result = "–ß–∏—Å—Ç—ã–π" if prob < 0.5 else "–ì—Ä—è–∑–Ω—ã–π" # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–π—Ç–µ, –µ—Å–ª–∏ –∫–ª–∞—Å—Å—ã –ø–µ—Ä–µ–ø—É—Ç–∞–Ω—ã
    cleanliness_confidence = 1 - prob if prob < 0.5 else prob
    
    # 2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
    detector_model = load_detector()
    image_for_detector = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    detection_results = detector_model(image_for_detector)[0]
    
    # 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    annotated_image = detection_results.plot() # YOLOv8 –∏–º–µ–µ—Ç —É–¥–æ–±–Ω—ã–π –º–µ—Ç–æ–¥ plot
    annotated_image = Image.fromarray(annotated_image[..., ::-1]) # BGR -> RGB

    num_damages = len(detection_results.boxes)
    integrity_result = "–¶–µ–ª—ã–π" if num_damages == 0 else "–ï—Å—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è"
    
    return cleanliness_result, cleanliness_confidence, integrity_result, num_damages, annotated_image

# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit ---
st.set_page_config(layout="wide", page_title="–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è")
st.title("üöó –°–∏—Å—Ç–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è")
st.write("–ü—Ä–æ—Ç–æ—Ç–∏–ø –¥–ª—è —Ö–∞–∫–∞—Ç–æ–Ω–∞ inDrive. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∞–≤—Ç–æ–º–æ–±–∏–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image_bytes = uploaded_file.getvalue()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        st.image(image_bytes, use_column_width=True)

    with col2:
        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        with st.spinner('–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...'):
            clean_res, clean_conf, int_res, int_num, ann_img = predict(image_bytes)
            
            st.metric(label="–ß–∏—Å—Ç–æ—Ç–∞", value=clean_res)
            st.metric(label="–¶–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å", value=int_res, delta=f"-{int_num} –¥–µ—Ñ–µ–∫—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ" if int_num > 0 else "–î–µ—Ñ–µ–∫—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

            st.image(ann_img, caption="–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è", use_column_width=True)